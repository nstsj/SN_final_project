{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "node2vec-neat.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LyKLqSnBfpA1",
        "a4LGWNp5gsmh",
        "nlJZZlsRhKNk",
        "q5CbQ9WGkHDV",
        "8TSBdRrBlW03",
        "UxLt1nORl8xh"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nstsj/SN_final_project/blob/master/node2vec_neat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xra1CVnsqWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all imports are here\n",
        "\n",
        "import networkx as nx\n",
        "# !pip3 install node2vec # un-comment if necessary\n",
        "from node2vec import Node2Vec\n",
        "import json\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from random import choice\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyKLqSnBfpA1",
        "colab_type": "text"
      },
      "source": [
        "## Let's create all the necessary functions:\n",
        "\n",
        "```recall``` & ```precision``` for evaluation\n",
        "\n",
        "```authors_to_emb``` speaks for itself\n",
        "\n",
        "```all_coauthors_pairs``` and ```random_not_coauthors``` to experiment on graphs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOtm1YvssqWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall(y_true, y_pred):\n",
        "    \"\"\"Recall metric.\n",
        "\n",
        "    Only computes a batch-wise average of recall.\n",
        "\n",
        "    Computes the recall, a metric for multi-label classification of\n",
        "    how many relevant items are selected.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "\n",
        "    Only computes a batch-wise average of precision.\n",
        "\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def authors_to_emb(authors, embs):\n",
        "    try:\n",
        "        out = list(embs[authors[0]])\n",
        "        out.extend(list(embs[authors[1]]))\n",
        "        return out\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "\n",
        "def all_coauthors_pairs(coauthors, exception_graph=None):\n",
        "    if len(coauthors) < 2:\n",
        "        return None\n",
        "    pairs = []\n",
        "    for i in range(len(coauthors)):\n",
        "        for j in range(len(coauthors[i + 1:])):\n",
        "            if exception_graph:\n",
        "                try:\n",
        "                    dist = nx.shortest_path_length(graph, coauthors[i], coauthors[i + j + 1])\n",
        "                except:\n",
        "                    dist = 100\n",
        "                if dist != 1:\n",
        "                    pairs.append([coauthors[i], coauthors[i + j + 1]])\n",
        "            else:\n",
        "                pairs.append([coauthors[i], coauthors[i + j + 1]])\n",
        "    return pairs\n",
        "\n",
        "\n",
        "def random_not_coauthors(graph, need_num, authors):\n",
        "    pairs = []\n",
        "    for _ in range(need_num * 4):\n",
        "        a1 = choice(list(graph.nodes()))\n",
        "        a2 = choice(list(graph.nodes()))\n",
        "        \n",
        "        try:\n",
        "            dist = nx.shortest_path_length(graph, a1, a2)\n",
        "        except:\n",
        "            dist = 100\n",
        "        if (not a1 == a2) and (dist > 1) and (a1 in authors) and (a2 in authors):\n",
        "            pairs.append([a1, a2])\n",
        "        if len(pairs) >= need_num:\n",
        "            break\n",
        "    return pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4LGWNp5gsmh",
        "colab_type": "text"
      },
      "source": [
        "## uncomment and use these cells if you're running code from Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2HdzT5suPKu",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6288cc31-3469-4baa-deeb-e3d23db56f17"
      },
      "source": [
        "#from google.colab import files\n",
        "#files.upload()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5969adae-e80a-44cf-bdeb-486ffd89af6b\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-5969adae-e80a-44cf-bdeb-486ffd89af6b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving arxivData.json to arxivData.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JutRA9EyywKY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f2df547-9f95-49f5-b690-ccabb3fe0443"
      },
      "source": [
        "#! ls #let's check that it's really here"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "arxivData.json\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlJZZlsRhKNk",
        "colab_type": "text"
      },
      "source": [
        "## main part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LYmwHr6sqWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# opening the file locally, creating our dataset\n",
        "\n",
        "with open('arxivData.json') as json_data:\n",
        "    dataset = json.load(json_data)\n",
        "    json_data.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "oBo4o-vcsqWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# making a raw graph \n",
        "\n",
        "graph = nx.Graph()\n",
        "authors = set([])\n",
        "X_train_val = []\n",
        "y_train_val = []\n",
        "for paper in dataset:\n",
        "    if 2014 <= paper['year'] <= 2016: # filtering by year\n",
        "        try:\n",
        "            paper_authors = []\n",
        "            for author in json.loads(re.sub(\"'\", '\"', paper['author'])):\n",
        "                paper_authors.append(author['name'])\n",
        "            if len(paper_authors) > 1:\n",
        "                authors.update(paper_authors)\n",
        "            coauthors = all_coauthors_pairs(paper_authors)\n",
        "            for pair in coauthors:\n",
        "                graph.add_edge(pair[0], pair[1])\n",
        "            X_train_val.extend(coauthors)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "\n",
        "data_size = len(X_train_val)\n",
        "X_train_val.extend(random_not_coauthors(graph, data_size * 1, authors))\n",
        "\n",
        "y_train_val = [[0.0, 1.0]] * data_size\n",
        "y_train_val.extend([[1.0, 0.0]] * (len(X_train_val) - data_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiuBVoGeh2-6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aff584da-83ed-4250-db10-326c561ab4d5"
      },
      "source": [
        "data_size # let's look at it"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13887"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "C_zYYXmKsqW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "graph_test = nx.Graph()\n",
        "X_test = []\n",
        "y_test = []\n",
        "for paper in dataset:\n",
        "    if paper['year'] >= 2017:\n",
        "        try:\n",
        "            paper_authors = []\n",
        "            for author in json.loads(re.sub(\"'\", '\"', paper['author'])):\n",
        "                if author['name'] in authors:\n",
        "                    paper_authors.append(author['name'])\n",
        "            coauthors = all_coauthors_pairs(paper_authors)\n",
        "            for pair in coauthors:\n",
        "                graph_test.add_edge(pair[0], pair[1])\n",
        "            X_test.extend(all_coauthors_pairs(paper_authors, graph))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "\n",
        "data_size = len(X_test)\n",
        "X_test.extend(random_not_coauthors(graph_test, data_size*5, authors))\n",
        "\n",
        "y_test = [[0.0, 1.0]] * data_size\n",
        "y_test.extend([[1.0, 0.0]] * (len(X_test) - data_size))\n",
        "\n",
        "X_test_raw = X_test\n",
        "y_test_raw = y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87GvruNFsqW7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask_valid = [(pair[0] in authors and pair[1] in authors) for pair in X_test_raw]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MByfKO3sqW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_valid = list(np.array(X_test_raw)[mask_valid])\n",
        "y_test_valid = list(np.array(y_test_raw)[mask_valid])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFKAm9hhsqXD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "891befc9-71cb-4354-831e-82858430ae98"
      },
      "source": [
        "preds_nx = [pred for _, _, pred in nx.jaccard_coefficient(graph, [x for x in X_test_raw])]\n",
        "\n",
        "y_test = [np.argmax(y) for y in np.array(y_test_raw)]\n",
        "\n",
        "y_pred = [1 if pred >= 0.5 else 0 for pred in preds_nx]\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('\\n')\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(roc_auc_score(y_test, preds_nx))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.91     69435\n",
            "           1       0.92      0.00      0.01     13887\n",
            "\n",
            "    accuracy                           0.83     83322\n",
            "   macro avg       0.88      0.50      0.46     83322\n",
            "weighted avg       0.85      0.83      0.76     83322\n",
            "\n",
            "\n",
            "\n",
            "[[69430     5]\n",
            " [13832    55]]\n",
            "0.5989623392410661\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5CbQ9WGkHDV",
        "colab_type": "text"
      },
      "source": [
        "### node2vec \n",
        "let's sample our graph by generating random walks from each node of the graph\n",
        "\n",
        "we'll use [node2vec](https://github.com/eliorc/node2vec) library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dd38MOspsqXG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "63ca395a-c8eb-4dac-d98c-4192b6e31ec5"
      },
      "source": [
        "# print('Generate walks')\n",
        "node2vec = Node2Vec(graph, dimensions=20, walk_length=16, num_walks=10, workers=10)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing transition probabilities:   0%|          | 31/24475 [00:00<01:19, 308.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generate walks\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Computing transition probabilities: 100%|██████████| 24475/24475 [00:08<00:00, 2749.85it/s]\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-26-6f1d20845d69>\", line 2, in <module>\n",
            "    node2vec = Node2Vec(graph, dimensions=20, walk_length=16, num_walks=10, workers=10)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/node2vec/node2vec.py\", line 67, in __init__\n",
            "    self.walks = self._generate_walks()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/node2vec/node2vec.py\", line 154, in _generate_walks\n",
            "    in enumerate(num_walks_lists, 1))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 1017, in __call__\n",
            "    self.retrieve()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 909, in retrieve\n",
            "    self._output.extend(job.get(timeout=self.timeout))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 562, in wrap_future_result\n",
            "    return future.result(timeout=timeout)\n",
            "  File \"/usr/lib/python3.6/concurrent/futures/_base.py\", line 427, in result\n",
            "    self._condition.wait(timeout)\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 295, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1452, in getframeinfo\n",
            "    lines, lnum = findsource(frame)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 170, in findsource\n",
            "    file = getsourcefile(object) or getfile(object)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 732, in getmodule\n",
            "    for modname, module in list(sys.modules.items()):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnOBxM2DsqXJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37240169-073d-4714-84f2-0e47f28275cc"
      },
      "source": [
        "\n",
        "print('Learn embeddings')\n",
        "embs = node2vec.fit(window=10, min_count=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learn embeddings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TSBdRrBlW03",
        "colab_type": "text"
      },
      "source": [
        "### let's create our NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AmtIXlpsqXM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "b7e03056-4ea3-4220-800e-7068133da9f8"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(40))\n",
        "model.add(Dense(30, activation='tanh'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "# model.add(Dense(10, activation='exponential'))  ### Вот этот слой лишний. Возможно активация не очень.\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer='rmsprop', metrics=[\"accuracy\"])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "JUxiednysqXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's train it \n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
        "X_train = np.array([authors_to_emb(pair, embs) for pair in X_train])\n",
        "y_train = np.array(y_train)\n",
        "X_val = np.array([authors_to_emb(pair, embs) for pair in X_val])\n",
        "y_val = np.array(y_val)\n",
        "model.fit(X_train, y_train, batch_size=128, epochs=40, validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxLt1nORl8xh",
        "colab_type": "text"
      },
      "source": [
        "### Let's test it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "071aRAF6sqXT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "7652302f-9b6c-4bb3-c774-8330a614a171"
      },
      "source": [
        "# 1 - соавторы, 0 - нет\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.99      0.99      0.99     15866\n",
        "#            1       0.99      0.99      0.99     15712\n",
        "\n",
        "#    micro avg       0.99      0.99      0.99     31578\n",
        "#    macro avg       0.99      0.99      0.99     31578\n",
        "# weighted avg       0.99      0.99      0.99     31578\n",
        "# [[15652   214]\n",
        "#  [  155 15557]]\n",
        "# 0.9989353879890981\n",
        "\n",
        "\n",
        "y_pred = [np.argmax(y) for y in model.predict(X_val)]\n",
        "y_true = [np.argmax(y) for y in y_val]\n",
        "print(classification_report(y_true, y_pred))\n",
        "print('\\n')\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(roc_auc_score(y_true, [proba[1] for proba in model.predict(X_val)]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98     15866\n",
            "           1       0.99      0.98      0.98     15712\n",
            "\n",
            "    accuracy                           0.98     31578\n",
            "   macro avg       0.98      0.98      0.98     31578\n",
            "weighted avg       0.98      0.98      0.98     31578\n",
            "\n",
            "\n",
            "\n",
            "[[15640   226]\n",
            " [  261 15451]]\n",
            "0.9979556622122701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2d51LFAsqXZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "c23fc17d-ee27-4f4f-de0c-73633f0d777a"
      },
      "source": [
        "# nx.resource_allocation_index\n",
        "#               precision    recall  f1-score   support\n",
        "#            0       0.83      1.00      0.91     69435\n",
        "#            1       0.76      0.00      0.00     13887\n",
        "\n",
        "#    micro avg       0.83      0.83      0.83     83322\n",
        "#    macro avg       0.80      0.50      0.46     83322\n",
        "# weighted avg       0.82      0.83      0.76     83322\n",
        "# [[69429     6]\n",
        "#  [13868    19]]\n",
        "# 0.5990594303456509\n",
        "\n",
        "# nx.jaccard_coefficient \n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.83      1.00      0.91     69435\n",
        "#            1       1.00      0.00      0.01     13887\n",
        "\n",
        "#    micro avg       0.83      0.83      0.83     83322\n",
        "#    macro avg       0.92      0.50      0.46     83322\n",
        "# weighted avg       0.86      0.83      0.76     83322\n",
        "# [[69435     0]\n",
        "#  [13832    55]]\n",
        "# 0.5990585638635837\n",
        "\n",
        "\n",
        "# 1*1 Logreg\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.86      0.99      0.92     69353\n",
        "#            1       0.83      0.19      0.31     13887\n",
        "\n",
        "#    micro avg       0.86      0.86      0.86     83240\n",
        "#    macro avg       0.84      0.59      0.62     83240\n",
        "# weighted avg       0.85      0.86      0.82     83240\n",
        "# [[68812   541]\n",
        "#  [11241  2646]]\n",
        "# 0.6395078283412827\n",
        "\n",
        "# 5*1 All_pairs\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.92      0.98      0.95    135084\n",
        "#            1       0.84      0.59      0.69     27216\n",
        "\n",
        "#    micro avg       0.91      0.91      0.91    162300\n",
        "#    macro avg       0.88      0.78      0.82    162300\n",
        "# weighted avg       0.91      0.91      0.91    162300\n",
        "# [[132044   3040]\n",
        "#  [ 11130  16086]]\n",
        "\n",
        "# 5*1 New pairs\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.87      0.98      0.92     69367\n",
        "#            1       0.68      0.24      0.35     13887\n",
        "\n",
        "#    micro avg       0.85      0.85      0.85     83254\n",
        "#    macro avg       0.77      0.61      0.64     83254\n",
        "# weighted avg       0.83      0.85      0.82     83254\n",
        "# [[67779  1588]\n",
        "#  [10569  3318]]\n",
        "# 0.6553634735001194\n",
        "\n",
        "# Random\n",
        "#              precision    recall  f1-score   support\n",
        "\n",
        "#            0       1.00      0.79      0.88     83254\n",
        "#            1       0.00      0.00      0.00         0\n",
        "\n",
        "#    micro avg       0.79      0.79      0.79     83254\n",
        "#    macro avg       0.50      0.39      0.44     83254\n",
        "# weighted avg       1.00      0.79      0.88     83254\n",
        "# [[65546 17708]\n",
        "#  [    0     0]]\n",
        "\n",
        "# 1*1 New pairs\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.87      0.95      0.91     69353\n",
        "#            1       0.55      0.29      0.38     13887\n",
        "\n",
        "#    micro avg       0.84      0.84      0.84     83240\n",
        "#    macro avg       0.71      0.62      0.65     83240\n",
        "# weighted avg       0.82      0.84      0.82     83240\n",
        "# [[66055  3298]\n",
        "#  [ 9823  4064]]\n",
        "# 0.6657878721401573\n",
        "\n",
        "# 1*1 New pairs Stack more layers 40e\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.87      0.96      0.91     69341\n",
        "#            1       0.59      0.30      0.39     13887\n",
        "\n",
        "#    micro avg       0.85      0.85      0.85     83228\n",
        "#    macro avg       0.73      0.63      0.65     83228\n",
        "# weighted avg       0.82      0.85      0.83     83228\n",
        "# [[66511  2830]\n",
        "#  [ 9789  4098]]\n",
        "# 0.7027983388267736\n",
        "\n",
        "# 1*1 New pairs Stack MORE layers 40e\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.87      0.97      0.92     69341\n",
        "#            1       0.64      0.27      0.38     13887\n",
        "\n",
        "#    micro avg       0.85      0.85      0.85     83228\n",
        "#    macro avg       0.75      0.62      0.65     83228\n",
        "# weighted avg       0.83      0.85      0.83     83228\n",
        "# [[67246  2095]\n",
        "#  [10151  3736]]\n",
        "# 0.6888330186522706\n",
        "\n",
        "mask_valid = [np.array(authors_to_emb(pair, embs)).shape == (40,) for pair in X_test_raw]\n",
        "X_test = np.array([authors_to_emb(pair, embs) for pair in X_test_raw\n",
        "                   if np.array(authors_to_emb(pair, embs)).shape == (40,)])\n",
        "y_test = np.array(y_test_raw)[mask_valid]\n",
        "y_pred = [np.argmax(y) for y in model.predict(X_test)]\n",
        "y_true = [np.argmax(y) for y in y_test]\n",
        "print(classification_report(y_true, y_pred))\n",
        "print('\\n')\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(roc_auc_score(y_true, [proba[1] for proba in model.predict(X_test)]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.97      0.92     69435\n",
            "           1       0.62      0.28      0.38     13887\n",
            "\n",
            "    accuracy                           0.85     83322\n",
            "   macro avg       0.74      0.62      0.65     83322\n",
            "weighted avg       0.83      0.85      0.83     83322\n",
            "\n",
            "\n",
            "\n",
            "[[67057  2378]\n",
            " [10011  3876]]\n",
            "0.7030813657929027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5JEH_satsqXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
        "X_train = np.array([cosine_similarity(embs.wv.__getitem__(pair[0]).reshape(1, -1),\n",
        "                                      embs.wv.__getitem__(pair[1]).reshape(1, -1))[0] for pair in X_train])\n",
        "y_train = [np.argmax(y) for y in y_train]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ovaaL52sqXi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "30612f7a-e523-4b9c-aa61-14aa7e4da2f8"
      },
      "source": [
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "upHoPMchsqXl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "773ff284-a3c0-4bd8-c30e-b25352df718e"
      },
      "source": [
        "X_val = np.array([cosine_similarity(embs.wv.__getitem__(pair[0]).reshape(1, -1),\n",
        "                                      embs.wv.__getitem__(pair[1]).reshape(1, -1))[0] for pair in X_val])\n",
        "y_val = [np.argmax(y) for y in y_val]\n",
        "\n",
        "y_pred = log_reg.predict(X_val)\n",
        "print(classification_report(y_val, y_pred))\n",
        "print('\\n')\n",
        "print(confusion_matrix(y_val, y_pred))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99     15866\n",
            "           1       0.99      0.99      0.99     15712\n",
            "\n",
            "    accuracy                           0.99     31578\n",
            "   macro avg       0.99      0.99      0.99     31578\n",
            "weighted avg       0.99      0.99      0.99     31578\n",
            "\n",
            "\n",
            "\n",
            "[[15770    96]\n",
            " [   97 15615]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "CfkAuGwbsqXp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "4321f8d3-74ed-4b42-bd32-b7daec579849"
      },
      "source": [
        "X_test = np.array([cosine_similarity(embs.wv.__getitem__(pair[0]).reshape(1, -1),\n",
        "                                      embs.wv.__getitem__(pair[1]).reshape(1, -1))[0] \n",
        "                   for pair in np.array(X_test_raw)[mask_valid]])\n",
        "y_test = [np.argmax(y) for y in np.array(y_test_raw)[mask_valid]]\n",
        "\n",
        "y_pred = log_reg.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('\\n')\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(roc_auc_score(y_test, [proba[1] for proba in log_reg.predict_proba(X_test)]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.99      0.92     69435\n",
            "           1       0.82      0.19      0.30     13887\n",
            "\n",
            "    accuracy                           0.86     83322\n",
            "   macro avg       0.84      0.59      0.61     83322\n",
            "weighted avg       0.85      0.86      0.82     83322\n",
            "\n",
            "\n",
            "\n",
            "[[68888   547]\n",
            " [11316  2571]]\n",
            "0.648030013611339\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}